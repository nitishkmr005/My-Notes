Computer Vision with CNN
-------------------------

SVM dont scale with volume of data 

Deep Learning - 

RNN
LSTM
CNN 

CNN => 

Image Classification, 
Object detection/Localization/Segmentation, 
Similarity Learning, 
Image captioning(NLP+CV), 
Generative Modeling, 
Video Analysis

Layers are with specilized functionality => Convolution, pooling, batch normalization, dense neural networks 
CNN works with volume but DNN can work with only flattened array

Connet does only feature extraction using Convolution, pooling and classification is done by DNN 
Layers does filtering and extracts features 

Digital Image
--------------
- 2D discrete space (only integral values) 
- Digitization (Sampling process) 
- Amplitude Quanitization

Image Processing => Color(RGB) to grey conversion needs to be done using python 

Digital image sizing - 
----------------------
Every color needs 3bytes 
Every grey scale needs 1byte 

Image as a function - 
Pixel intensity number of electrons captured in the wells 

Edges as Features - 
---------------------
To define the boundary, pixel intensity needs to changes 
Check if pixel belongs to an edge 

Digital Noise 
--------------
- Digital noise due to dark current can artificially create edges where there are none. If these noisy edges are not taken care of, the CNN algorithm can misinterpret them as genuine edges
- Thermal noise due to heating of the devices. The heat kicks out additional electrons from the sensors along with the electrons generated by photoelectric effect.
- Unwanted pixel intensity change causes digital noise 
- Gaussian Blurring reduces digital noise 

Image Filters 
Feature Map 

Horizontal scan given vertical edges and vertical scan gives horizontal edges 
Mixing two functions is convolution => Original input and transformation function 

- CNN uses sharing of weights 
- CNN has specialization layers
- CNN uses volumes instead of vectors or arrays 

Convulution Layers and Filter/Kernel 
-------------------------------------
5*5*3 filter (smaller than input dimension) to feel the edges 
3 Feature maps  => Horizontal, Vertical and Angular 
Gabor Features => Atomic level features 

Kernel/Filter => 3*3 or 5*5 => Number in Kernels are weights => This weight matrix is shared across all neurons => This is weight sharing 
These Filter weights are calculated by backpropagation 
Number of filters is hyperparameter => More the complex image more the number of filters 
To not lose information on edges of image, padding is used
CNN is positional invariant (doesnt matter position of object) 
Each image is divided into blocks/grid and each is given to each neurons 
Size of the image, Size of the filter, size of stride => Decides number of neurons 
Rank 2 tensor => Matrix, Rank 3 tensor => Volume  
As many features apllied on input we get as many feature maps => 3 filters => 3 feature maps 
one grid of image was applied on all 3 filters => 3 layers(3 feature maps) => one volume
True edge remains same in grey scale or color image of RGB 
RGB image => R image, G Image, B Image (one filter is applied on all 3 images => 3 feature maps are added together giving single feature map) 
Stride = 1 skip 1st column 
Image centering 
Size of the new image in row and column is given by Rnew = ((image_rows – filter_rows) / stride) + 1. Similarly, Cnew =  ((image_cols – filter_cols)/stride) + 1
Local Receptive Field for the neuron => Grid where neuron applies filter on and calculates one cell value of the Feature Map/Activation map 
Filter is a set of kernels 
For CNN if ReLU is not working => Try with Leaky ReLU 

Pooling Layers
----------------

Does similar to Feature Selection 
Lot of redundancy generated my feature map of convolution layer 
Feature map is a coordinate where there are gradients (Change in pixel intensity) 
Average and Max Pooling => Small grids with 2*2 size are created on Feature map => In every grid what is the average/max of gradient => Unwanted features are elemeneted 
Every pixel in Feature Map is Gradient  
Because of stride => Two arrows are overlapping => There redundant features 
Max pooling is preferred pooling over average pooling 
Pooling layers dont use any weights 
Size of Feature Map = 28*28 => Number of neurons = 784 
In Pooling layer, stride is 2 by default 

Hyperparameter Tuning
-----------------------

Padding=same => Padding is yes o/p=i/p
Padding=valid => Padding is no 
CNN performs better than DNN 
CNN depends on change in pixel intensity and DNN depends on pixel intensity 
Initially less number of filters and less kernel size 
Next CNN conv layers, increase filter count and kernel size 

Image Size = 28*28 (30*30 if padding is 'same')
Number of Kernels = 64
Kernel Size = 3 
Stride size = 1 
Padding = By default it adds 2 rows and 2 cols around the input image (when padding='same') 
Number of weights parameters = 3*3*64 (Number of i/p channels(3 for RGB)*Number of o/p channels(Number of filters)*H*Wof Kernel)
Size of feature map  = (30-3)/1 (Stride) + 1 = 28*28 
Number of convolution neurons = 28*28 = 784 neurons 
Pool size = 2 

- In CNN architectures, pooling is typically performed with 2x2 windows, stride 2 and no padding. While convolution is done with 3x3 windows, stride 1 and with padding.
- The output of both convolution and pooling layers are 3D volumes, but a fully connected layer expects a 1D vector of numbers. So we flatten the output of the final pooling layer to a vector and that becomes the input to the fully connected layer.
- A CNN model can be thought as a combination of two components: feature extraction part and the classification part.
- In CNN architectures the first layers usually act as edge detectors. Deeper feature maps encode high level concepts like “cat nose” or “dog ear” while lower level feature maps detect simple edges and shapes. That’s why deeper feature maps contain less information about the image. 

https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2
https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification

https://dgschwend.github.io/netscope/#/editor  => Tool to analyze deep networks 